<!DOCTYPE html><html lang="en" class="scroll-smooth"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/f6c8eb37d788b6a5.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-679b75d1c4c2027c.js"/><script src="/_next/static/chunks/4bd1b696-70b6d399998de86a.js" async=""></script><script src="/_next/static/chunks/684-5aaa8290a129f299.js" async=""></script><script src="/_next/static/chunks/main-app-c0edd855fd4de48f.js" async=""></script><script src="/_next/static/chunks/17-9c04c9413a9f9f1f.js" async=""></script><script src="/_next/static/chunks/874-6cc630662f3664af.js" async=""></script><script src="/_next/static/chunks/862-15038af301665bb3.js" async=""></script><script src="/_next/static/chunks/app/layout-7eaa2dfd13e092db.js" async=""></script><script src="/_next/static/chunks/178-595a94b9af1e67b5.js" async=""></script><script src="/_next/static/chunks/748-2db3a9d7664fb123.js" async=""></script><script src="/_next/static/chunks/app/%5Bslug%5D/page-cce46a678fd58b2c.js" async=""></script><link rel="icon" href="/leaf.svg" type="image/svg+xml"/><link rel="dns-prefetch" href="https://google-fonts.jialeliu.com"/><link rel="preconnect" href="https://google-fonts.jialeliu.com" crossorigin=""/><link rel="preload" as="style" href="https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&amp;family=Crimson+Text:ital,wght@0,400;0,600;1,400&amp;display=swap"/><link rel="stylesheet" id="gfonts-css" href="https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&amp;family=Crimson+Text:ital,wght@0,400;0,600;1,400&amp;display=swap" media="print"/><script>
              (function(){
                var l = document.getElementById('gfonts-css');
                if (!l) return;
                if (l.media !== 'all') {
                  l.addEventListener('load', function(){ try { l.media = 'all'; } catch(e){} });
                }
              })();
            </script><noscript><link rel="stylesheet" href="https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&amp;family=Crimson+Text:ital,wght@0,400;0,600;1,400&amp;display=swap"/></noscript><script>
              try {
                const theme = localStorage.getItem('theme-storage');
                const parsed = theme ? JSON.parse(theme) : null;
                const setting = parsed?.state?.theme || 'system';
                const prefersDark = typeof window !== 'undefined' && window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));
                var root = document.documentElement;
                root.classList.add(effective);
                root.setAttribute('data-theme', effective);
              } catch (e) {
                var root = document.documentElement;
                root.classList.add('light');
                root.setAttribute('data-theme', 'light');
              }
            </script><title>Publications | Yongchao He</title><meta name="description" content="A collection of my research work."/><meta name="author" content="Yongchao He"/><meta name="keywords" content="Yongchao He,PhD,Research,"/><meta name="creator" content="Yongchao He"/><meta name="publisher" content="Yongchao He"/><meta property="og:title" content="Yongchao He"/><meta property="og:description" content="PhD student at the University of Example."/><meta property="og:site_name" content="Yongchao He&#x27;s Academic Website"/><meta property="og:locale" content="en_US"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Yongchao He"/><meta name="twitter:description" content="PhD student at the University of Example."/><link rel="icon" href="/leaf.svg"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="font-sans antialiased"><div style="visibility:hidden"><nav class="fixed top-0 left-0 right-0 z-50" data-headlessui-state=""><div class="transition-all duration-300 ease-out bg-transparent" style="transform:translateY(-100px)"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex justify-between items-center h-16 lg:h-20"><div class="flex-shrink-0" tabindex="0"><a class="text-xl lg:text-2xl font-serif font-semibold text-primary hover:text-accent transition-colors duration-200" href="/">Yongchao He</a></div><div class="hidden lg:block"><div class="ml-10 flex items-center space-x-8"><div class="flex items-baseline space-x-8"><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/"><span class="relative z-10">About</span></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-primary" href="/publications/"><span class="relative z-10">Publications</span><div class="absolute inset-0 bg-accent/10 rounded-lg"></div></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/projects/"><span class="relative z-10">Projects</span></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/awards/"><span class="relative z-10">Awards</span></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/services/"><span class="relative z-10">Services</span></a></div><div class="flex items-center justify-center w-10 h-10 rounded-lg border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] bg-background dark:bg-neutral-800"><div class="w-4 h-4 rounded-full bg-neutral-300 animate-pulse"></div></div></div></div><div class="lg:hidden flex items-center space-x-2"><div class="flex items-center justify-center w-10 h-10 rounded-lg border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] bg-background dark:bg-neutral-800"><div class="w-4 h-4 rounded-full bg-neutral-300 animate-pulse"></div></div><button class="inline-flex items-center justify-center p-2 rounded-md text-neutral-600 hover:text-primary hover:bg-neutral-100 dark:hover:bg-neutral-800 focus:outline-none focus:ring-2 focus:ring-inset focus:ring-accent transition-colors duration-200" id="headlessui-disclosure-button-«R5pdb»" type="button" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Open main menu</span><div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="block h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></div></button></div></div></div></div></nav><main class="min-h-screen pt-16 lg:pt-20"><div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-12"><div style="opacity:0;transform:translateY(20px)"><div class="mb-8"><h1 class="text-4xl font-serif font-bold text-primary mb-4">Publications</h1><p class="text-lg text-neutral-600 dark:text-neutral-500 max-w-2xl">A collection of my research work.</p></div><div class="mb-8 space-y-4"><div class="flex flex-col sm:flex-row gap-4"><div class="relative flex-grow"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="absolute left-3 top-1/2 transform -translate-y-1/2 h-5 w-5 text-neutral-400"><path stroke-linecap="round" stroke-linejoin="round" d="m21 21-5.197-5.197m0 0A7.5 7.5 0 1 0 5.196 5.196a7.5 7.5 0 0 0 10.607 10.607Z"></path></svg><input type="text" placeholder="Search publications..." class="w-full pl-10 pr-4 py-2 rounded-lg border border-neutral-200 dark:border-neutral-800 bg-white dark:bg-neutral-900 focus:ring-2 focus:ring-accent focus:border-transparent transition-all duration-200" value=""/></div><button class="flex items-center justify-center px-4 py-2 rounded-lg border transition-all duration-200 bg-white dark:bg-neutral-900 border-neutral-200 dark:border-neutral-800 text-neutral-600 hover:border-accent hover:text-accent"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-5 w-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3c2.755 0 5.455.232 8.083.678.533.09.917.556.917 1.096v1.044a2.25 2.25 0 0 1-.659 1.591l-5.432 5.432a2.25 2.25 0 0 0-.659 1.591v2.927a2.25 2.25 0 0 1-1.244 2.013L9.75 21v-6.568a2.25 2.25 0 0 0-.659-1.591L3.659 7.409A2.25 2.25 0 0 1 3 5.818V4.774c0-.54.384-1.006.917-1.096A48.32 48.32 0 0 1 12 3Z"></path></svg>Filters</button></div></div><div class="space-y-6"><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="L4: Low-Latency and Load-Balanced LLM Serving via Length-Aware Scheduling" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/L4.pdf"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">L4: Low-Latency and Load-Balanced LLM Serving via Length-Aware Scheduling</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class=" ">Yitao Yuan</span>, </span><span><span class=" ">Chenqi Zhao</span>, </span><span><span class=" ">Bohan Zhao</span>, </span><span><span class=" ">Zane Cao</span>, </span><span><span class="font-semibold text-accent ">Yongchao He</span>, </span><span><span class=" ">Wenfei Wu</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3"> <!-- -->2025</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://arxiv.org/abs/2512.19179" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M19.5 14.25v-2.625a3.375 3.375 0 0 0-3.375-3.375h-1.5A1.125 1.125 0 0 1 13.5 7.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H8.25m0 12.75h7.5m-7.5 3H12M10.5 2.25H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 0 0-9-9Z"></path></svg>Abstract</button><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="A Unified Sparse Attention via Multi-Granularity Compression" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/Unisparse.pdf"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">A Unified Sparse Attention via Multi-Granularity Compression</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class=" ">Siran Liu</span>, </span><span><span class=" ">Zane Cao</span>, </span><span><span class="font-semibold text-accent ">Yongchao He</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3"> <!-- -->2025</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://arxiv.org/abs/2512.14082" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M19.5 14.25v-2.625a3.375 3.375 0 0 0-3.375-3.375h-1.5A1.125 1.125 0 0 1 13.5 7.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H8.25m0 12.75h7.5m-7.5 3H12M10.5 2.25H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 0 0-9-9Z"></path></svg>Abstract</button><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="SIMPLE: Disaggregating Sampling from GPU Inference into a Decision Plane for Faster Distributed LLM Serving" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/simple.pdf"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">SIMPLE: Disaggregating Sampling from GPU Inference into a Decision Plane for Faster Distributed LLM Serving</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class=" ">Bohan Zhao</span>, </span><span><span class=" ">Zane Cao</span>, </span><span><span class="font-semibold text-accent ">Yongchao He</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3"> <!-- -->2025</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://arxiv.org/abs/2512.00719" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M19.5 14.25v-2.625a3.375 3.375 0 0 0-3.375-3.375h-1.5A1.125 1.125 0 0 1 13.5 7.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H8.25m0 12.75h7.5m-7.5 3H12M10.5 2.25H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 0 0-9-9Z"></path></svg>Abstract</button><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">MegatronApp: Efficient and Comprehensive Management on Distributed LLM Training</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class=" ">Bohan Zhao</span>, </span><span><span class=" ">Guang Yang</span>, </span><span><span class=" ">Shuo Chen</span>, </span><span><span class=" ">Ruitao Liu</span>, </span><span><span class=" ">Tingrui Zhang</span>, </span><span><span class="font-semibold text-accent ">Yongchao He</span>, </span><span><span class=" ">Wei Xu</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3"> <!-- -->2025</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://arxiv.org/abs/2507.19845" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M19.5 14.25v-2.625a3.375 3.375 0 0 0-3.375-3.375h-1.5A1.125 1.125 0 0 1 13.5 7.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H8.25m0 12.75h7.5m-7.5 3H12M10.5 2.25H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 0 0-9-9Z"></path></svg>Abstract</button><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="SiPipe: Bridging the CPU-GPU Utilization Gap for Efficient Pipeline-Parallel LLM Inference" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/sipipe.pdf"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">SiPipe: Bridging the CPU-GPU Utilization Gap for Efficient Pipeline-Parallel LLM Inference</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="font-semibold text-accent ">Yongchao He</span>, </span><span><span class=" ">Bohan Zhao</span>, </span><span><span class=" ">Zheng Cao</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3"> <!-- -->2025</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://arxiv.org/abs/2506.22033" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M19.5 14.25v-2.625a3.375 3.375 0 0 0-3.375-3.375h-1.5A1.125 1.125 0 0 1 13.5 7.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H8.25m0 12.75h7.5m-7.5 3H12M10.5 2.25H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 0 0-9-9Z"></path></svg>Abstract</button><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="HeteroSpec: Leveraging Contextual Heterogeneity for Efficient Speculative Decoding" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/heterospec.pdf"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">HeteroSpec: Leveraging Contextual Heterogeneity for Efficient Speculative Decoding</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class=" ">Siran Liu</span>, </span><span><span class=" ">Yang Ye</span>, </span><span><span class=" ">Qianchao Zhu</span>, </span><span><span class=" ">Zane Cao</span>, </span><span><span class="font-semibold text-accent ">Yongchao He</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3"> <!-- -->2025</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://arxiv.org/abs/2505.13254" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M19.5 14.25v-2.625a3.375 3.375 0 0 0-3.375-3.375h-1.5A1.125 1.125 0 0 1 13.5 7.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H8.25m0 12.75h7.5m-7.5 3H12M10.5 2.25H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 0 0-9-9Z"></path></svg>Abstract</button><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">RateSheriff: Multipath Flow-aware and Resource Efficient Rate Limiter Placement for Data Center Networks</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class=" ">Songshi Dou</span>, </span><span><span class="font-semibold text-accent ">Yongchao He</span>, </span><span><span class=" ">Sen Liu</span>, </span><span><span class=" ">Wenfei Wu</span>, </span><span><span class=" ">Zehua Guo</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">2023 IEEE/ACM 31st International Symposium on Quality of Service (IWQoS)<!-- --> <!-- -->2023</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://doi.org/10.1109/IWQoS57198.2023.10188742" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">DOI</a><a href="https://ieeexplore.ieee.org/abstract/document/10188742" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="A Generic Service to Provide In-Network Aggregation for Key-Value Streams" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/ASK.pdf"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">A Generic Service to Provide In-Network Aggregation for Key-Value Streams</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="font-semibold text-accent ">Yongchao He</span>, </span><span><span class=" ">Wenfei Wu</span>, </span><span><span class=" ">Yanfang Le</span>, </span><span><span class=" ">Ming Liu</span>, </span><span><span class=" ">ChonLam Lao</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems<!-- --> <!-- -->2023</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://doi.org/10.1145/3575693.3575708" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">DOI</a><a href="https://doi.org/10.1145/3575693.3575708" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M19.5 14.25v-2.625a3.375 3.375 0 0 0-3.375-3.375h-1.5A1.125 1.125 0 0 1 13.5 7.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H8.25m0 12.75h7.5m-7.5 3H12M10.5 2.25H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 0 0-9-9Z"></path></svg>Abstract</button><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">Consistent and Fine-Grained Rule Update with In-Network Control for Distributed Rate Limiting</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="font-semibold text-accent ">Yongchao He</span>, </span><span><span class=" ">Wenfei Wu</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">2022 IEEE/ACM 30th International Symposium on Quality of Service (IWQoS)<!-- --> <!-- -->2022</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://doi.org/10.1109/IWQoS54832.2022.9812884" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">DOI</a><a href="https://ieeexplore.ieee.org/document/9812884" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">SFP: Service Function Chain Provision on Programmable Switches for Cloud Tenants</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class=" ">Hongyi Huang</span>, </span><span><span class=" ">Wenfei Wu</span>, </span><span><span class="font-semibold text-accent ">Yongchao He</span>, </span><span><span class=" ">Zehua Guo</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">2022 IEEE International Parallel and Distributed Processing Symposium (IPDPS)<!-- --> <!-- -->2022</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://doi.org/10.1109/IPDPS53621.2022.00123" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">DOI</a><a href="https://ieeexplore.ieee.org/document/9820721" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="Scalable On-Switch Rate Limiters for the Cloud" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/switchrl.pdf"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">Scalable On-Switch Rate Limiters for the Cloud</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="font-semibold text-accent ">Yongchao He</span>, </span><span><span class=" ">Wenfei Wu</span>, </span><span><span class=" ">Xuemin Wen</span>, </span><span><span class=" ">Haifeng Li</span>, </span><span><span class=" ">Yongqiang Yang</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">IEEE INFOCOM 2021 - IEEE Conference on Computer Communications<!-- --> <!-- -->2021</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://doi.org/10.1109/INFOCOM42981.2021.9488773" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">DOI</a><a href="https://dl.acm.org/doi/abs/10.1109/INFOCOM42981.2021.9488773" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="NFD: Using Behavior Models to Develop Cross-Platform Network Functions" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/nfd.pdf"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">NFD: Using Behavior Models to Develop Cross-Platform Network Functions</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class=" ">Hongyi Huang</span>, </span><span><span class=" ">Wenfei Wu</span>, </span><span><span class="font-semibold text-accent ">Yongchao He</span>, </span><span><span class=" ">Bangwen Deng</span>, </span><span><span class=" ">Ying Zhang</span>, </span><span><span class=" ">Yongqiang Xiong</span>, </span><span><span class=" ">Guo Chen</span>, </span><span><span class=" ">Yong Cui</span>, </span><span><span class=" ">Peng Cheng</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">IEEE INFOCOM 2021 - IEEE Conference on Computer Communications<!-- --> <!-- -->2021</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://doi.org/10.1109/INFOCOM42981.2021.9488734" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">DOI</a><a href="https://dl.acm.org/doi/10.1145/3342280.3342342" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">Fully Functional Rate Limiter Design on Programmable Hardware Switches</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="font-semibold text-accent ">Yongchao He</span>, </span><span><span class=" ">Wenfei Wu</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">Proceedings of the ACM SIGCOMM 2019 Conference Posters and Demos<!-- --> <!-- -->2019</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://doi.org/10.1145/3342280.3342344" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">DOI</a><a href="https://doi.org/10.1145/3342280.3342344" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">SpeedyBox: Low-Latency NFV Service Chains with Cross-NF Runtime Consolidation</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class=" ">Yimin Jiang</span>, </span><span><span class=" ">Yong Cui</span>, </span><span><span class=" ">Wenfei Wu</span>, </span><span><span class=" ">Zhe Xu</span>, </span><span><span class=" ">Jiahan Gu</span>, </span><span><span class=" ">K. K. Ramakrishnan</span>, </span><span><span class="font-semibold text-accent ">Yongchao He</span>, </span><span><span class=" ">Xuehai Qian</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)<!-- --> <!-- -->2019</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://doi.org/10.1109/ICDCS.2019.00016" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">DOI</a><a href="https://ieeexplore.ieee.org/document/8885120" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Paper</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div></div></div></div><!--$--><!--/$--><!--$--><!--/$--></main><footer class="border-t border-neutral-200/50 bg-neutral-50/50 dark:bg-neutral-900/50 dark:border-neutral-700/50"><div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-6"><div class="flex flex-col sm:flex-row justify-between items-center gap-2"><p class="text-xs text-neutral-500">Last updated: <!-- -->Dec 27, 2025</p></div></div></footer></div><script src="/_next/static/chunks/webpack-679b75d1c4c2027c.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[3719,[\"17\",\"static/chunks/17-9c04c9413a9f9f1f.js\",\"874\",\"static/chunks/874-6cc630662f3664af.js\",\"862\",\"static/chunks/862-15038af301665bb3.js\",\"177\",\"static/chunks/app/layout-7eaa2dfd13e092db.js\"],\"ThemeProvider\"]\n3:I[768,[\"17\",\"static/chunks/17-9c04c9413a9f9f1f.js\",\"874\",\"static/chunks/874-6cc630662f3664af.js\",\"862\",\"static/chunks/862-15038af301665bb3.js\",\"177\",\"static/chunks/app/layout-7eaa2dfd13e092db.js\"],\"default\"]\n4:I[7555,[],\"\"]\n5:I[1295,[],\"\"]\n6:I[2548,[\"17\",\"static/chunks/17-9c04c9413a9f9f1f.js\",\"874\",\"static/chunks/874-6cc630662f3664af.js\",\"862\",\"static/chunks/862-15038af301665bb3.js\",\"177\",\"static/chunks/app/layout-7eaa2dfd13e092db.js\"],\"default\"]\n8:I[9665,[],\"MetadataBoundary\"]\na:I[9665,[],\"OutletBoundary\"]\nd:I[4911,[],\"AsyncMetadataOutlet\"]\nf:I[9665,[],\"ViewportBoundary\"]\n11:I[6614,[],\"\"]\n:HL[\"/_next/static/css/f6c8eb37d788b6a5.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"umVLTIsTSv7jKry7v7CRh\",\"p\":\"\",\"c\":[\"\",\"publications\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[[\"slug\",\"publications\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/f6c8eb37d788b6a5.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"scroll-smooth\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/leaf.svg\",\"type\":\"image/svg+xml\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://google-fonts.jialeliu.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://google-fonts.jialeliu.com\",\"crossOrigin\":\"\"}],[\"$\",\"link\",null,{\"rel\":\"preload\",\"as\":\"style\",\"href\":\"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700\u0026family=Crimson+Text:ital,wght@0,400;0,600;1,400\u0026display=swap\"}],[\"$\",\"link\",null,{\"rel\":\"stylesheet\",\"id\":\"gfonts-css\",\"href\":\"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700\u0026family=Crimson+Text:ital,wght@0,400;0,600;1,400\u0026display=swap\",\"media\":\"print\"}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              (function(){\\n                var l = document.getElementById('gfonts-css');\\n                if (!l) return;\\n                if (l.media !== 'all') {\\n                  l.addEventListener('load', function(){ try { l.media = 'all'; } catch(e){} });\\n                }\\n              })();\\n            \"}}],[\"$\",\"noscript\",null,{\"children\":[\"$\",\"link\",null,{\"rel\":\"stylesheet\",\"href\":\"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700\u0026family=Crimson+Text:ital,wght@0,400;0,600;1,400\u0026display=swap\"}]}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              try {\\n                const theme = localStorage.getItem('theme-storage');\\n                const parsed = theme ? JSON.parse(theme) : null;\\n                const setting = parsed?.state?.theme || 'system';\\n                const prefersDark = typeof window !== 'undefined' \u0026\u0026 window.matchMedia \u0026\u0026 window.matchMedia('(prefers-color-scheme: dark)').matches;\\n                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));\\n                var root = document.documentElement;\\n                root.classList.add(effective);\\n                root.setAttribute('data-theme', effective);\\n              } catch (e) {\\n                var root = document.documentElement;\\n                root.classList.add('light');\\n                root.setAttribute('data-theme', 'light');\\n              }\\n            \"}}]]}],[\"$\",\"body\",null,{\"className\":\"font-sans antialiased\",\"children\":[\"$\",\"$L2\",null,{\"children\":[[\"$\",\"$L3\",null,{\"items\":[{\"title\":\"About\",\"type\":\"page\",\"target\":\"about\",\"href\":\"/\"},{\"title\":\"Publications\",\"type\":\"page\",\"target\":\"publications\",\"href\":\"/publications\"},{\"title\":\"Projects\",\"type\":\"page\",\"target\":\"projects\",\"href\":\"/projects\"},{\"title\":\"Awards\",\"type\":\"page\",\"target\":\"awards\",\"href\":\"/awards\"},{\"title\":\"Services\",\"type\":\"page\",\"target\":\"services\",\"href\":\"/services\"}],\"siteTitle\":\"Yongchao He\",\"enableOnePageMode\":false}],[\"$\",\"main\",null,{\"className\":\"min-h-screen pt-16 lg:pt-20\",\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"$L6\",null,{\"lastUpdated\":\"Dec 27, 2025\"}]]}]}]]}]]}],{\"children\":[[\"slug\",\"publications\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L7\",[\"$\",\"$L8\",null,{\"children\":\"$L9\"}],null,[\"$\",\"$La\",null,{\"children\":[\"$Lb\",\"$Lc\",[\"$\",\"$Ld\",null,{\"promise\":\"$@e\"}]]}]]}],{},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"m94RMj-6sNjVA19f9ZFJE\",{\"children\":[[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],null]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$11\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"12:\"$Sreact.suspense\"\n13:I[4911,[],\"AsyncMetadata\"]\n15:I[6669,[\"17\",\"static/chunks/17-9c04c9413a9f9f1f.js\",\"178\",\"static/chunks/178-595a94b9af1e67b5.js\",\"748\",\"static/chunks/748-2db3a9d7664fb123.js\",\"182\",\"static/chunks/app/%5Bslug%5D/page-cce46a678fd58b2c.js\"],\"default\"]\n9:[\"$\",\"$12\",null,{\"fallback\":null,\"children\":[\"$\",\"$L13\",null,{\"promise\":\"$@14\"}]}]\n16:T580,Efficiently harnessing GPU compute is critical to improving user experience and reducing operational costs in large language model (LLM) services. However, current inference engine schedulers overlook the attention backend's sensitivity to request-length heterogeneity within a batch. As state-of-the-art models now support context windows exceeding 128K tokens, this once-tolerable inefficiency has escalated into a primary system bottleneck, causing severe performance degradation through GPU underutilization and increased latency. We present L4, a runtime system that dynamically reschedules requests across multiple instances serving the same LLM to mitigate per-instance length heterogeneity. L4 partitions these instances into length-specialized groups, each handling requests within a designated length range, naturally forming a pipeline as requests flow through them. L4 devises a dynamic programming algorithm to efficiently find the stage partition with the best QoE, employs runtime range refinement together with decentralized load (re)balance both across and within groups, achieving a balanced and efficient multi-instance service. Our evaluation shows that, under the same configuration, L4 reduces end-to-end latency by up to 67% and tail latency by up to 69%, while improving overall system throughput by up to 2.89 times compared to the state-of-the-art multi-instance scheduling systems.17:T701,@misc{yuan2025l4lowlatencyloadbalancedllm,\n  title = {L4: Low-Latency and Load-Balanced LLM Serving via Length-Aware Scheduling},\n  author = {Yitao Yuan and Chenqi Zhao and Bohan Zhao and Zane Cao and Yongchao He and Wenfei Wu},\n  year = {2025},\n  eprint = {2512.191"])</script><script>self.__next_f.push([1,"79},\n  archivePrefix = {arXiv},\n  primaryClass = {cs.DC},\n  abstract = {Efficiently harnessing GPU compute is critical to improving user experience and reducing operational costs in large language model (LLM) services. However, current inference engine schedulers overlook the attention backend's sensitivity to request-length heterogeneity within a batch. As state-of-the-art models now support context windows exceeding 128K tokens, this once-tolerable inefficiency has escalated into a primary system bottleneck, causing severe performance degradation through GPU underutilization and increased latency. We present L4, a runtime system that dynamically reschedules requests across multiple instances serving the same LLM to mitigate per-instance length heterogeneity. L4 partitions these instances into length-specialized groups, each handling requests within a designated length range, naturally forming a pipeline as requests flow through them. L4 devises a dynamic programming algorithm to efficiently find the stage partition with the best QoE, employs runtime range refinement together with decentralized load (re)balance both across and within groups, achieving a balanced and efficient multi-instance service. Our evaluation shows that, under the same configuration, L4 reduces end-to-end latency by up to 67% and tail latency by up to 69%, while improving overall system throughput by up to 2.89 times compared to the state-of-the-art multi-instance scheduling systems.},\n  url = {https://arxiv.org/abs/2512.19179}\n}18:T539,Efficient long-context understanding and reasoning are increasingly vital for large language model (LLM) applications such as multi-turn dialogue and program analysis. However, the core self-attention mechanism scales quadratically with sequence length, creating a fundamental computational bottleneck. Existing sparse attention methods alleviate this issue but face trade-offs: training-based methods are costly and cannot be directly applied as acceleration plugins for other models, while inference-time method"])</script><script>self.__next_f.push([1,"s often compromise efficiency or cross-modal generality. To address these limitations, we present UniSparse, a unified mechanism that introduces the notion of composite tokens--compact representations that aggregate multi-granularity contextual information. Building on this abstraction, UniSparse dynamically constructs sparse attention through multi-granularity compression and block-level selection, enabling efficient and hardware-friendly execution on GPU. Across multiple modalities and tasks ranging from synthetic benchmarks to real-world applications, UniSparse consistently surpasses state-of-the-art sparse attention methods (e.g., MInference, XAttention, FlexPrefill) in both accuracy and efficiency, achieving ≥ 99% of full-attention accuracy and up to 2.61× faster attention computation than FlashAttention.19:T689,@misc{liu2025unifiedsparseattentionmultigranularity,\n  title = {A Unified Sparse Attention via Multi-Granularity Compression},\n  author = {Siran Liu and Zane Cao and Yongchao He},\n  year = {2025},\n  eprint = {2512.14082},\n  archivePrefix = {arXiv},\n  primaryClass = {cs.CL},\n  abstract = {Efficient long-context understanding and reasoning are increasingly vital for large language model (LLM) applications such as multi-turn dialogue and program analysis. However, the core self-attention mechanism scales quadratically with sequence length, creating a fundamental computational bottleneck. Existing sparse attention methods alleviate this issue but face trade-offs: training-based methods are costly and cannot be directly applied as acceleration plugins for other models, while inference-time methods often compromise efficiency or cross-modal generality. To address these limitations, we present UniSparse, a unified mechanism that introduces the notion of composite tokens--compact representations that aggregate multi-granularity contextual information. Building on this abstraction, UniSparse dynamically constructs sparse attention through multi-granularity compression and block-level selection, enabling ef"])</script><script>self.__next_f.push([1,"ficient and hardware-friendly execution on GPU. Across multiple modalities and tasks ranging from synthetic benchmarks to real-world applications, UniSparse consistently surpasses state-of-the-art sparse attention methods (e.g., MInference, XAttention, FlexPrefill) in both accuracy and efficiency, achieving ≥ 99% of full-attention accuracy and up to 2.61× faster attention computation than FlashAttention.},\n  url = {https://arxiv.org/abs/2512.14082}\n}1a:T58d,As large language models (LLMs) scale out with tensor parallelism (TP) and pipeline parallelism (PP) and production stacks have aggressively optimized the data plane (attention/GEMM and KV cache), sampling, the decision plane that turns logits into tokens, becomes a new bottleneck. This creates a structural holdout: sampling neither expands with TP nor balances across PP stages, so its share of iteration time grows as GPUs get faster and it caps pipeline frequency at the last stage. We present SIMPLE, a stage-agnostic, sequence-parallel, overlappable decision plane that disaggregates sampling into a CPU-side service and shrinks its runtime footprint back to a minor, hidden role. SIMPLE combines: (1) sequence-parallel sampling, which shards work along the batch dimension and removes vocabulary-axis collectives; (2) a CPU-based algorithm with column-wise penalties and truncation-first filtering to realize single-pass, linear-time kernels; and (3) speculative hot-vocab sampling (SHVS), which samples on a small hot set with rejection-correctness and uses a simple sizing model to choose the hot-vocab size that maximizes throughput. In evaluation, SIMPLE improves end-to-end throughput by up to 96% and reduces P95 latency by 20-65%. Crucially, SIMPLE requires no user-side code changes and composes with existing data-plane optimizations, unlocking scaling benefits that compound with future GPU generations.1b:T707,@misc{zhao2025simpledisaggregatingsamplinggpu,\n  title = {SIMPLE: Disaggregating Sampling from GPU Inference into a Decision Plane for Faster Distributed "])</script><script>self.__next_f.push([1,"LLM Serving},\n  author = {Bohan Zhao and Zane Cao and Yongchao He},\n  year = {2025},\n  eprint = {2512.00719},\n  archivePrefix = {arXiv},\n  primaryClass = {cs.DC},\n  abstract = {As large language models (LLMs) scale out with tensor parallelism (TP) and pipeline parallelism (PP) and production stacks have aggressively optimized the data plane (attention/GEMM and KV cache), sampling, the decision plane that turns logits into tokens, becomes a new bottleneck. This creates a structural holdout: sampling neither expands with TP nor balances across PP stages, so its share of iteration time grows as GPUs get faster and it caps pipeline frequency at the last stage. We present SIMPLE, a stage-agnostic, sequence-parallel, overlappable decision plane that disaggregates sampling into a CPU-side service and shrinks its runtime footprint back to a minor, hidden role. SIMPLE combines: (1) sequence-parallel sampling, which shards work along the batch dimension and removes vocabulary-axis collectives; (2) a CPU-based algorithm with column-wise penalties and truncation-first filtering to realize single-pass, linear-time kernels; and (3) speculative hot-vocab sampling (SHVS), which samples on a small hot set with rejection-correctness and uses a simple sizing model to choose the hot-vocab size that maximizes throughput. In evaluation, SIMPLE improves end-to-end throughput by up to 96% and reduces P95 latency by 20-65%. Crucially, SIMPLE requires no user-side code changes and composes with existing data-plane optimizations, unlocking scaling benefits that compound with future GPU generations.},\n  url = {https://arxiv.org/abs/2512.00719}\n}1c:T561,@misc{zhao2025megatronappefficientcomprehensivemanagement,\n  title = {MegatronApp: Efficient and Comprehensive Management on Distributed LLM Training},\n  author = {Bohan Zhao and Guang Yang and Shuo Chen and Ruitao Liu and Tingrui Zhang and Yongchao He and Wei Xu},\n  year = {2025},\n  eprint = {2507.19845},\n  archivePrefix = {arXiv},\n  primaryClass = {cs.DC},\n  abstract = {The rapid escalation"])</script><script>self.__next_f.push([1," in the parameter count of large language models (LLMs) has transformed model training from a single-node endeavor into a highly intricate, cross-node activity. While frameworks such as Megatron-LM successfully integrate tensor (TP), pipeline (PP), and data (DP) parallelism to enable trillion-parameter training, they simultaneously expose practitioners to unprecedented systems-level challenges in performance optimization, diagnosis, and interpretability. MegatronApp is an open-source toolchain expressly designed to meet these challenges. It introduces four orthogonal, yet seamlessly composable modules--MegaScan, MegaFBD, MegaDPP, and MegaScope--that collectively elevate the reliability, efficiency, and transparency of production-scale training. This paper presents the motivation, architecture, and distinctive contributions of each module, and elucidates how their synergistic integration augments the Megatron-LM ecosystem.},\n  url = {https://arxiv.org/abs/2507.19845}\n}1d:T43e,As inference workloads for large language models (LLMs) scale to meet growing user demand, pipeline parallelism (PP) has become a widely adopted strategy for multi-GPU deployment, particularly in cross-node setups, to improve key-value (KV) cache capacity and inference throughput. However, PP suffers from inherent inefficiencies caused by three types of execution bubbles-load-imbalance, intra-stage, and inter-stage-which limit pipeline saturation. We present SiPipe, a heterogeneous pipeline design that improves throughput by leveraging underutilized CPU resources to offload auxiliary computation and communication. SiPipe incorporates three key techniques-CPU sampling, a token-safe execution model, and structure-aware transmission-to mitigate pipeline bubbles and improve execution efficiency. Across diverse LLMs, SiPipe achieves up to 2.1 times higher throughput, 43% lower per-token latency, and up to 23% higher average GPU utilization compared to the state-of-the-art vLLM under the same PP configuration, demonstrating its generality across LL"])</script><script>self.__next_f.push([1,"Ms and deployment scenarios.1e:T5a6,@misc{he2025sipipebridgingcpugpuutilization,\n  title = {SiPipe: Bridging the CPU-GPU Utilization Gap for Efficient Pipeline-Parallel LLM Inference},\n  author = {Yongchao He and Bohan Zhao and Zheng Cao},\n  year = {2025},\n  eprint = {2506.22033},\n  archivePrefix = {arXiv},\n  primaryClass = {cs.DC},\n  abstract = {As inference workloads for large language models (LLMs) scale to meet growing user demand, pipeline parallelism (PP) has become a widely adopted strategy for multi-GPU deployment, particularly in cross-node setups, to improve key-value (KV) cache capacity and inference throughput. However, PP suffers from inherent inefficiencies caused by three types of execution bubbles-load-imbalance, intra-stage, and inter-stage-which limit pipeline saturation. We present SiPipe, a heterogeneous pipeline design that improves throughput by leveraging underutilized CPU resources to offload auxiliary computation and communication. SiPipe incorporates three key techniques-CPU sampling, a token-safe execution model, and structure-aware transmission-to mitigate pipeline bubbles and improve execution efficiency. Across diverse LLMs, SiPipe achieves up to 2.1 times higher throughput, 43% lower per-token latency, and up to 23% higher average GPU utilization compared to the state-of-the-art vLLM under the same PP configuration, demonstrating its generality across LLMs and deployment scenarios.},\n  url = {https://arxiv.org/abs/2506.22033}\n}1f:T544,Autoregressive decoding inherently limits the inference throughput of Large Language Model (LLM) due to its sequential dependency. Speculative decoding mitigates this by verifying multiple predicted tokens in parallel, but its efficiency remains constrained by what we identify as verification heterogeneity -- the uneven difficulty of verifying different speculative candidates. In practice, a small subset of high-confidence predictions accounts for most successful verifications, yet existing methods treat all candidates uniformly, leading to redundant c"])</script><script>self.__next_f.push([1,"omputation. We present HeteroSpec, a heterogeneity-adaptive speculative decoding framework that allocates verification effort in proportion to candidate uncertainty. HeteroSpec estimates verification complexity using a lightweight entropy-based quantifier, partitions candidates via a data-driven stratification policy, and dynamically tunes speculative depth and pruning thresholds through coordinated optimization. Across five benchmarks and four LLMs, HeteroSpec delivers an average 4.24× decoding speedup over state-of-the-art methods such as EAGLE-3, while preserving exact output distributions. Crucially, HeteroSpec requires no model retraining and remains compatible with other inference optimizations, making it a practical direction for improving speculative decoding efficiency.20:T6cc,@misc{liu2025heterospecleveragingcontextualheterogeneity,\n  title = {HeteroSpec: Leveraging Contextual Heterogeneity for Efficient Speculative Decoding},\n  author = {Siran Liu and Yang Ye and Qianchao Zhu and Zane Cao and Yongchao He},\n  year = {2025},\n  eprint = {2505.13254},\n  archivePrefix = {arXiv},\n  primaryClass = {cs.CL},\n  abstract = {Autoregressive decoding inherently limits the inference throughput of Large Language Model (LLM) due to its sequential dependency. Speculative decoding mitigates this by verifying multiple predicted tokens in parallel, but its efficiency remains constrained by what we identify as verification heterogeneity -- the uneven difficulty of verifying different speculative candidates. In practice, a small subset of high-confidence predictions accounts for most successful verifications, yet existing methods treat all candidates uniformly, leading to redundant computation. We present HeteroSpec, a heterogeneity-adaptive speculative decoding framework that allocates verification effort in proportion to candidate uncertainty. HeteroSpec estimates verification complexity using a lightweight entropy-based quantifier, partitions candidates via a data-driven stratification policy, and dynamically tunes specu"])</script><script>self.__next_f.push([1,"lative depth and pruning thresholds through coordinated optimization. Across five benchmarks and four LLMs, HeteroSpec delivers an average 4.24× decoding speedup over state-of-the-art methods such as EAGLE-3, while preserving exact output distributions. Crucially, HeteroSpec requires no model retraining and remains compatible with other inference optimizations, making it a practical direction for improving speculative decoding efficiency.},\n  url = {https://arxiv.org/abs/2505.13254}\n}21:T503,Key-value stream aggregation is a common operation in distributed systems, which requires intensive computation and network resources. We propose a generic in-network aggregation service for key-value streams, ASK, to accelerate the aggregation operations in diverse distributed applications. ASK is a switch-host co-designed system, where the programmable switch provides a best-effort aggregation service, and the host runs a daemon to interact with applications. ASK makes in-depth optimization tailored to traffic characteristics, hardware restrictions, and network unreliable natures: it vectorizes multiple key-value tuples’ aggregation of one packet in one switch pipeline pass, which improves the per-host’s goodput; it develops a lightweight reliability mechanism for key-value stream’s asynchronous aggregation, which guarantees computation correctness; it designs a hot-key agnostic prioritization for key-skewed workloads, which improves the switch memory utilization. We prototype ASK and use it to support Spark and BytePS. The evaluation shows that ASK could accelerate pure key-value aggregation tasks by up to 155 times and big data jobs by 3-5 times, and be backward compatible with existing INA-empowered distributed training solutions with the same speedup.22:T7ba,@inproceedings{10.1145/3575693.3575708,\n  author = {He, Yongchao and Wu, Wenfei and Le, Yanfang and Liu, Ming and Lao, ChonLam},\n  title = {A Generic Service to Provide In-Network Aggregation for Key-Value Streams},\n  year = {2023},\n  isbn = {9781450399166},\n"])</script><script>self.__next_f.push([1,"  publisher = {Association for Computing Machinery},\n  address = {New York, NY, USA},\n  url = {https://doi.org/10.1145/3575693.3575708},\n  doi = {10.1145/3575693.3575708},\n  abstract = {Key-value stream aggregation is a common operation in distributed systems, which requires intensive computation and network resources. We propose a generic in-network aggregation service for key-value streams, ASK, to accelerate the aggregation operations in diverse distributed applications. ASK is a switch-host co-designed system, where the programmable switch provides a best-effort aggregation service, and the host runs a daemon to interact with applications. ASK makes in-depth optimization tailored to traffic characteristics, hardware restrictions, and network unreliable natures: it vectorizes multiple key-value tuples’ aggregation of one packet in one switch pipeline pass, which improves the per-host’s goodput; it develops a lightweight reliability mechanism for key-value stream’s asynchronous aggregation, which guarantees computation correctness; it designs a hot-key agnostic prioritization for key-skewed workloads, which improves the switch memory utilization. We prototype ASK and use it to support Spark and BytePS. The evaluation shows that ASK could accelerate pure key-value aggregation tasks by up to 155 times and big data jobs by 3-5 times, and be backward compatible with existing INA-empowered distributed training solutions with the same speedup.},\n  booktitle = {Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},\n  pages = {33–47},\n  numpages = {15},\n  location = {Vancouver, BC, Canada},\n  series = {ASPLOS 2023}\n}"])</script><script>self.__next_f.push([1,"7:[\"$\",\"div\",null,{\"className\":\"max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-12\",\"children\":[[\"$\",\"$L15\",null,{\"config\":{\"type\":\"publication\",\"title\":\"Publications\",\"description\":\"A collection of my research work.\",\"source\":\"publications.bib\"},\"publications\":[{\"id\":\"yuan2025l4lowlatencyloadbalancedllm\",\"title\":\"L4: Low-Latency and Load-Balanced LLM Serving via Length-Aware Scheduling\",\"authors\":[{\"name\":\"Yitao Yuan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Chenqi Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Bohan Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zane Cao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yongchao He\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenfei Wu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"preprint\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$7:props:children:0:props:publications:0:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"\",\"conference\":\"\",\"url\":\"https://arxiv.org/abs/2512.19179\",\"abstract\":\"$16\",\"description\":\"\",\"selected\":true,\"preview\":\"L4.pdf\",\"bibtex\":\"$17\"},{\"id\":\"liu2025unifiedsparseattentionmultigranularity\",\"title\":\"A Unified Sparse Attention via Multi-Granularity Compression\",\"authors\":[{\"name\":\"Siran Liu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zane Cao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yongchao He\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"preprint\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$7:props:children:0:props:publications:1:tags\",\"researchArea\":\"transformer-architectures\",\"journal\":\"\",\"conference\":\"\",\"url\":\"https://arxiv.org/abs/2512.14082\",\"abstract\":\"$18\",\"description\":\"\",\"selected\":true,\"preview\":\"Unisparse.pdf\",\"bibtex\":\"$19\"},{\"id\":\"zhao2025simpledisaggregatingsamplinggpu\",\"title\":\"SIMPLE: Disaggregating Sampling from GPU Inference into a Decision Plane for Faster Distributed LLM Serving\",\"authors\":[{\"name\":\"Bohan Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zane Cao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yongchao He\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"preprint\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$7:props:children:0:props:publications:2:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"\",\"conference\":\"\",\"url\":\"https://arxiv.org/abs/2512.00719\",\"abstract\":\"$1a\",\"description\":\"\",\"selected\":false,\"preview\":\"simple.pdf\",\"bibtex\":\"$1b\"},{\"id\":\"zhao2025megatronappefficientcomprehensivemanagement\",\"title\":\"MegatronApp: Efficient and Comprehensive Management on Distributed LLM Training\",\"authors\":[{\"name\":\"Bohan Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Guang Yang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shuo Chen\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ruitao Liu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Tingrui Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yongchao He\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wei Xu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"preprint\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$7:props:children:0:props:publications:3:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"\",\"conference\":\"\",\"url\":\"https://arxiv.org/abs/2507.19845\",\"abstract\":\"The rapid escalation in the parameter count of large language models (LLMs) has transformed model training from a single-node endeavor into a highly intricate, cross-node activity. While frameworks such as Megatron-LM successfully integrate tensor (TP), pipeline (PP), and data (DP) parallelism to enable trillion-parameter training, they simultaneously expose practitioners to unprecedented systems-level challenges in performance optimization, diagnosis, and interpretability. MegatronApp is an open-source toolchain expressly designed to meet these challenges. It introduces four orthogonal, yet seamlessly composable modules--MegaScan, MegaFBD, MegaDPP, and MegaScope--that collectively elevate the reliability, efficiency, and transparency of production-scale training. This paper presents the motivation, architecture, and distinctive contributions of each module, and elucidates how their synergistic integration augments the Megatron-LM ecosystem.\",\"description\":\"\",\"selected\":false,\"bibtex\":\"$1c\"},{\"id\":\"he2025sipipebridgingcpugpuutilization\",\"title\":\"SiPipe: Bridging the CPU-GPU Utilization Gap for Efficient Pipeline-Parallel LLM Inference\",\"authors\":[{\"name\":\"Yongchao He\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Bohan Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zheng Cao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"preprint\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$7:props:children:0:props:publications:4:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"\",\"conference\":\"\",\"url\":\"https://arxiv.org/abs/2506.22033\",\"abstract\":\"$1d\",\"description\":\"\",\"selected\":true,\"preview\":\"sipipe.pdf\",\"bibtex\":\"$1e\"},{\"id\":\"liu2025heterospecleveragingcontextualheterogeneity\",\"title\":\"HeteroSpec: Leveraging Contextual Heterogeneity for Efficient Speculative Decoding\",\"authors\":[{\"name\":\"Siran Liu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yang Ye\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Qianchao Zhu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zane Cao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yongchao He\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"preprint\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$7:props:children:0:props:publications:5:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"\",\"conference\":\"\",\"url\":\"https://arxiv.org/abs/2505.13254\",\"abstract\":\"$1f\",\"description\":\"\",\"selected\":true,\"preview\":\"heterospec.pdf\",\"bibtex\":\"$20\"},{\"id\":\"10188742\",\"title\":\"RateSheriff: Multipath Flow-aware and Resource Efficient Rate Limiter Placement for Data Center Networks\",\"authors\":[{\"name\":\"Songshi Dou\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yongchao He\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Sen Liu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenfei Wu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zehua Guo\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2023,\"type\":\"conference\",\"status\":\"published\",\"tags\":[\"Data centers;Limiting;Simulation;Memory management;Switches;Quality of service;TCPIP\"],\"keywords\":\"$7:props:children:0:props:publications:6:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"\",\"conference\":\"2023 IEEE/ACM 31st International Symposium on Quality of Service (IWQoS)\",\"volume\":\"\",\"issue\":\"\",\"pages\":\"01-10\",\"doi\":\"10.1109/IWQoS57198.2023.10188742\",\"url\":\"https://ieeexplore.ieee.org/abstract/document/10188742\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"bibtex\":\"@INPROCEEDINGS{10188742,\\n  author = {Dou, Songshi and He, Yongchao and Liu, Sen and Wu, Wenfei and Guo, Zehua},\\n  booktitle = {2023 IEEE/ACM 31st International Symposium on Quality of Service (IWQoS)},\\n  title = {RateSheriff: Multipath Flow-aware and Resource Efficient Rate Limiter Placement for Data Center Networks},\\n  year = {2023},\\n  volume = {},\\n  number = {},\\n  pages = {01-10},\\n  doi = {10.1109/IWQoS57198.2023.10188742},\\n  url = {https://ieeexplore.ieee.org/abstract/document/10188742}\\n}\"},{\"id\":\"10.1145/3575693.3575708\",\"title\":\"A Generic Service to Provide In-Network Aggregation for Key-Value Streams\",\"authors\":[{\"name\":\"Yongchao He\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenfei Wu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yanfang Le\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ming Liu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"ChonLam Lao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2023,\"type\":\"conference\",\"status\":\"published\",\"tags\":[\"Big Data\",\"In-Network Aggregation\",\"Key-Value\",\"P4\"],\"keywords\":\"$7:props:children:0:props:publications:7:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"\",\"conference\":\"Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems\",\"pages\":\"33–47\",\"doi\":\"10.1145/3575693.3575708\",\"url\":\"https://doi.org/10.1145/3575693.3575708\",\"abstract\":\"$21\",\"description\":\"\",\"selected\":true,\"preview\":\"ASK.pdf\",\"bibtex\":\"$22\"},{\"id\":\"9812884\",\"title\":\"Consistent and Fine-Grained Rule Update with In-Network Control for Distributed Rate Limiting\",\"authors\":[{\"name\":\"Yongchao He\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenfei Wu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2022,\"type\":\"conference\",\"status\":\"published\",\"tags\":[\"Wide area networks;Cloud computing;Limiting;Process control;Bandwidth;Quality of service;Control systems\"],\"keywords\":\"$7:props:children:0:props:publications:8:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"\",\"conference\":\"2022 IEEE/ACM 30th International Symposium on Quality of Service (IWQoS)\",\"volume\":\"\",\"issue\":\"\",\"pages\":\"1-10\",\"doi\":\"10.1109/IWQoS54832.2022.9812884\",\"url\":\"https://ieeexplore.ieee.org/document/9812884\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"bibtex\":\"@INPROCEEDINGS{9812884,\\n  author = {He, Yongchao and Wu, Wenfei},\\n  booktitle = {2022 IEEE/ACM 30th International Symposium on Quality of Service (IWQoS)},\\n  title = {Consistent and Fine-Grained Rule Update with In-Network Control for Distributed Rate Limiting},\\n  year = {2022},\\n  volume = {},\\n  number = {},\\n  pages = {1-10},\\n  doi = {10.1109/IWQoS54832.2022.9812884},\\n  url = {https://ieeexplore.ieee.org/document/9812884}\\n}\"},{\"id\":\"9820721\",\"title\":\"SFP: Service Function Chain Provision on Programmable Switches for Cloud Tenants\",\"authors\":[{\"name\":\"Hongyi Huang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenfei Wu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yongchao He\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zehua Guo\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2022,\"type\":\"conference\",\"status\":\"published\",\"tags\":[\"Integer programming;Cloud computing;Runtime;Service function chaining;Pipelines;Prototypes;Process control;NFV;programmable switch\"],\"keywords\":\"$7:props:children:0:props:publications:9:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"\",\"conference\":\"2022 IEEE International Parallel and Distributed Processing Symposium (IPDPS)\",\"volume\":\"\",\"issue\":\"\",\"pages\":\"1239-1249\",\"doi\":\"10.1109/IPDPS53621.2022.00123\",\"url\":\"https://ieeexplore.ieee.org/document/9820721\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"bibtex\":\"@INPROCEEDINGS{9820721,\\n  author = {Huang, Hongyi and Wu, Wenfei and He, Yongchao and Guo, Zehua},\\n  booktitle = {2022 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},\\n  title = {SFP: Service Function Chain Provision on Programmable Switches for Cloud Tenants},\\n  year = {2022},\\n  volume = {},\\n  number = {},\\n  pages = {1239-1249},\\n  doi = {10.1109/IPDPS53621.2022.00123},\\n  url = {https://ieeexplore.ieee.org/document/9820721}\\n}\"},{\"id\":\"9488773\",\"title\":\"Scalable On-Switch Rate Limiters for the Cloud\",\"authors\":[{\"name\":\"Yongchao He\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenfei Wu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xuemin Wen\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Haifeng Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yongqiang Yang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2021,\"type\":\"conference\",\"status\":\"published\",\"tags\":[\"Limiting;Scalability;Conferences;Prototypes;Production;Channel allocation;Approximation algorithms\"],\"keywords\":\"$7:props:children:0:props:publications:10:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"\",\"conference\":\"IEEE INFOCOM 2021 - IEEE Conference on Computer Communications\",\"volume\":\"\",\"issue\":\"\",\"pages\":\"1-10\",\"doi\":\"10.1109/INFOCOM42981.2021.9488773\",\"url\":\"https://dl.acm.org/doi/abs/10.1109/INFOCOM42981.2021.9488773\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"preview\":\"switchrl.pdf\",\"bibtex\":\"@INPROCEEDINGS{9488773,\\n  author = {He, Yongchao and Wu, Wenfei and Wen, Xuemin and Li, Haifeng and Yang, Yongqiang},\\n  booktitle = {IEEE INFOCOM 2021 - IEEE Conference on Computer Communications},\\n  title = {Scalable On-Switch Rate Limiters for the Cloud},\\n  year = {2021},\\n  volume = {},\\n  number = {},\\n  pages = {1-10},\\n  doi = {10.1109/INFOCOM42981.2021.9488773},\\n  url = {https://dl.acm.org/doi/abs/10.1109/INFOCOM42981.2021.9488773}\\n}\"},{\"id\":\"9488734\",\"title\":\"NFD: Using Behavior Models to Develop Cross-Platform Network Functions\",\"authors\":[{\"name\":\"Hongyi Huang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenfei Wu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yongchao He\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Bangwen Deng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ying Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yongqiang Xiong\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Guo Chen\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yong Cui\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Peng Cheng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2021,\"type\":\"conference\",\"status\":\"published\",\"tags\":[\"Biological system modeling;Linux;Conferences;Computational modeling;Ecosystems;Prototypes;Graphics processing units\"],\"keywords\":\"$7:props:children:0:props:publications:11:tags\",\"researchArea\":\"signal-processing\",\"journal\":\"\",\"conference\":\"IEEE INFOCOM 2021 - IEEE Conference on Computer Communications\",\"volume\":\"\",\"issue\":\"\",\"pages\":\"1-10\",\"doi\":\"10.1109/INFOCOM42981.2021.9488734\",\"url\":\"https://dl.acm.org/doi/10.1145/3342280.3342342\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"preview\":\"nfd.pdf\",\"bibtex\":\"@INPROCEEDINGS{9488734,\\n  author = {Huang, Hongyi and Wu, Wenfei and He, Yongchao and Deng, Bangwen and Zhang, Ying and Xiong, Yongqiang and Chen, Guo and Cui, Yong and Cheng, Peng},\\n  booktitle = {IEEE INFOCOM 2021 - IEEE Conference on Computer Communications},\\n  title = {NFD: Using Behavior Models to Develop Cross-Platform Network Functions},\\n  year = {2021},\\n  volume = {},\\n  number = {},\\n  pages = {1-10},\\n  doi = {10.1109/INFOCOM42981.2021.9488734},\\n  url = {https://dl.acm.org/doi/10.1145/3342280.3342342}\\n}\"},{\"id\":\"10.1145/3342280.3342344\",\"title\":\"Fully Functional Rate Limiter Design on Programmable Hardware Switches\",\"authors\":[{\"name\":\"Yongchao He\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenfei Wu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2019,\"type\":\"conference\",\"status\":\"published\",\"tags\":[\"Network Function\",\"P4\",\"Rate Limiter\"],\"keywords\":\"$7:props:children:0:props:publications:12:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"\",\"conference\":\"Proceedings of the ACM SIGCOMM 2019 Conference Posters and Demos\",\"pages\":\"159–160\",\"doi\":\"10.1145/3342280.3342344\",\"url\":\"https://doi.org/10.1145/3342280.3342344\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"bibtex\":\"@inproceedings{10.1145/3342280.3342344,\\n  author = {He, Yongchao and Wu, Wenfei},\\n  title = {Fully Functional Rate Limiter Design on Programmable Hardware Switches},\\n  year = {2019},\\n  isbn = {9781450368865},\\n  publisher = {Association for Computing Machinery},\\n  address = {New York, NY, USA},\\n  url = {https://doi.org/10.1145/3342280.3342344},\\n  doi = {10.1145/3342280.3342344},\\n  booktitle = {Proceedings of the ACM SIGCOMM 2019 Conference Posters and Demos},\\n  pages = {159–160},\\n  numpages = {2},\\n  location = {Beijing, China},\\n  series = {SIGCOMM Posters and Demos '19}\\n}\"},{\"id\":\"8885120\",\"title\":\"SpeedyBox: Low-Latency NFV Service Chains with Cross-NF Runtime Consolidation\",\"authors\":[{\"name\":\"Yimin Jiang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yong Cui\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenfei Wu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zhe Xu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jiahan Gu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"K. K. Ramakrishnan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yongchao He\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xuehai Qian\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2019,\"type\":\"conference\",\"status\":\"published\",\"tags\":[\"Noise measurement;Runtime;Optimization;Redundancy;Network function virtualization;Acceleration;Aggregates;NFV;low-latency;service chain;consolidation\"],\"keywords\":\"$7:props:children:0:props:publications:13:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"\",\"conference\":\"2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)\",\"volume\":\"\",\"issue\":\"\",\"pages\":\"68-79\",\"doi\":\"10.1109/ICDCS.2019.00016\",\"url\":\"https://ieeexplore.ieee.org/document/8885120\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"bibtex\":\"@INPROCEEDINGS{8885120,\\n  author = {Jiang, Yimin and Cui, Yong and Wu, Wenfei and Xu, Zhe and Gu, Jiahan and Ramakrishnan, K. K. and He, Yongchao and Qian, Xuehai},\\n  booktitle = {2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)},\\n  title = {SpeedyBox: Low-Latency NFV Service Chains with Cross-NF Runtime Consolidation},\\n  year = {2019},\\n  volume = {},\\n  number = {},\\n  pages = {68-79},\\n  doi = {10.1109/ICDCS.2019.00016},\\n  url = {https://ieeexplore.ieee.org/document/8885120}\\n}\"}]}],false,false]}]\n"])</script><script>self.__next_f.push([1,"c:null\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\nb:null\n"])</script><script>self.__next_f.push([1,"14:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Publications | Yongchao He\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"A collection of my research work.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"author\",\"content\":\"Yongchao He\"}],[\"$\",\"meta\",\"3\",{\"name\":\"keywords\",\"content\":\"Yongchao He,PhD,Research,\"}],[\"$\",\"meta\",\"4\",{\"name\":\"creator\",\"content\":\"Yongchao He\"}],[\"$\",\"meta\",\"5\",{\"name\":\"publisher\",\"content\":\"Yongchao He\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:title\",\"content\":\"Yongchao He\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:description\",\"content\":\"PhD student at the University of Example.\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:site_name\",\"content\":\"Yongchao He's Academic Website\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"11\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:title\",\"content\":\"Yongchao He\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:description\",\"content\":\"PhD student at the University of Example.\"}],[\"$\",\"link\",\"14\",{\"rel\":\"icon\",\"href\":\"/leaf.svg\"}]],\"error\":null,\"digest\":\"$undefined\"}\ne:{\"metadata\":\"$14:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>